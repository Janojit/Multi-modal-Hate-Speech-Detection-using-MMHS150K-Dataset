# Multimodal Hate Speech Detection (MMHS150K)

This project implements multimodal hate speech detection using both **text** and **image** features from the MMHS150K dataset. It includes preprocessing, training, evaluation, and visualization scripts for **six different model architectures**.

---

## âš™ï¸ Setup

### ğŸ”¹ 1. Clone the Repository

```bash
git clone https://github.com/Janojit/Multi-modal-Hate-Speech-Detection-using-MMHS150K-Dataset multimodal-hate-speech
cd multimodal-hate-speech
```

### ğŸ”¹ 2. Create and Activate a Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### ğŸ”¹ 3. Install Requirements

```bash
pip install -r requirements.txt
```

### ğŸ”¹ 4. Download and Prepare the Dataset

Download the dataset manually from Kaggle:

ğŸ”— [MMHS150K - Multimodal Hate Speech Dataset](https://www.kaggle.com/datasets/victorcallejasf/multimodal-hate-speech)

Unzip and structure the contents as follows:

```
multimodal-hate-speech/
â”œâ”€â”€ img_resized/               # Folder containing resized tweet images (*.jpg)
â”œâ”€â”€ img_txt/                   # Folder for text extracted from images (if any)
â”œâ”€â”€ splits/                    # Data split IDs
â”‚   â”œâ”€â”€ train_ids.txt
â”‚   â”œâ”€â”€ val_ids.txt
â”‚   â””â”€â”€ test_ids.txt
â”œâ”€â”€ MMHS150K_GT.json           # Annotated dataset (JSON)
â”œâ”€â”€ hatespeech_keywords.txt    # Supplementary keyword list
â”œâ”€â”€ MMHS150K_readme.txt        # Original dataset readme
â”‚
â”œâ”€â”€ preprocess{i}.py               # Preprocess train split for model i
â”œâ”€â”€ preprocess_val{i}.py           # Preprocess val split for model i
â”œâ”€â”€ preprocess_test{i}.py          # Preprocess test split for model i
â”‚
â”œâ”€â”€ model{i}.py                    # MultiModalNet{i} architecture (i=1 to 6)
â”‚
â”œâ”€â”€ train.py                  # Train all 6 models
â”œâ”€â”€ evaluate.py               # Evaluate all 6 models on test set
â”œâ”€â”€ explore.py                # Show label distribution across splits
â”œâ”€â”€ requirements.txt          # Dependency list
â””â”€â”€ README.md                 # Project documentation
```

---

## ğŸ§ª Instructions

### ğŸ”¹ Step 1: Preprocess Features

Run the preprocessing for each model version (i=1 to 6):

```bash
python preprocess1.py && python preprocess_val1.py && python preprocess_test1.py
python preprocess2.py && python preprocess_val2.py && python preprocess_test2.py
...
python preprocess6.py && python preprocess_val6.py && python preprocess_test6.py
```

This generates:
- `preprocessed{i}_train.npz`, `preprocessed{i}_val.npz`, `preprocessed{i}_test.npz`

---

### ğŸ”¹ Step 2: Explore Data

```bash
python explore.py
```

Generates `split_class_distribution.jpg`

---

### ğŸ”¹ Step 3: Train All Models

```bash
python train.py
```

- Trains all `MultiModalNet{i}` models (i=1 to 6)
- Saves each as `model{i}.pth`
- Plots training vs validation loss as `model{i}_loss.jpg`

---

### ğŸ”¹ Step 4: Evaluate All Models

```bash
python evaluate.py
```

- Prints accuracy, precision, recall, and F1-score for each model
- Saves:
  - `evaluation_metrics_comparison.jpg`
  - `confusion_matrices_comparison.jpg`

---


## ğŸ‘¥ Authors

- Janojit Chakraborty â€” [GitHub](https://github.com/Janojit)
