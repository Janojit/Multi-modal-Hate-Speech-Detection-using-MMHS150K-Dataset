# Multimodal Hate Speech Detection (MMHS150K)

This project implements multimodal hate speech detection using both **text** (via BERT) and **image** (via ResNet18) features from the MMHS150K dataset. It includes preprocessing, training, evaluation, and visualization scripts for **six different model architectures**.

---

## ğŸ“ Project Structure

```
multimodal-hate-speech/
â”œâ”€â”€ data/                      # JSON data and ID splits (user-provided)
â”‚   â”œâ”€â”€ MMHS150K_GT.json
â”‚   â””â”€â”€ splits/
â”‚       â”œâ”€â”€ train_ids.txt
â”‚       â”œâ”€â”€ val_ids.txt
â”‚       â””â”€â”€ test_ids.txt
â”‚
â”œâ”€â”€ img_resized/              # Resized tweet images (*.jpg)
â”‚
â”œâ”€â”€ preprocess{i}.py               # Preprocess train split for model i
â”œâ”€â”€ preprocess_val{i}.py           # Preprocess val split for model i
â”œâ”€â”€ preprocess_test{i}.py          # Preprocess test split for model i
â”‚
â”œâ”€â”€ model{i}.py                    # MultiModalNet{i} architecture (i=1 to 6)
â”‚
â”œâ”€â”€ train.py                  # Train all 6 models
â”œâ”€â”€ evaluate.py               # Evaluate all 6 models on test set
â”œâ”€â”€ explore.py                # Show label distribution across splits
â”œâ”€â”€ requirements.txt          # Dependency list
â””â”€â”€ README.md                 # Project documentation
```

---

## âš™ï¸ Setup

```bash
pip install -r requirements.txt
```

### Folders

Ensure the following are present:

- `data/MMHS150K_GT.json`
- `data/splits/train_ids.txt`, `val_ids.txt`, `test_ids.txt`
- `img_resized/` with `{tweet_id}.jpg` files

---

## ğŸ§ª Instructions

### ğŸ”¹ Step 1: Preprocess Features

Run the preprocessing for each model version (i=1 to 6):

```bash
python preprocess1.py && python preprocess_val1.py && python preprocess_test1.py
python preprocess2.py && python preprocess_val2.py && python preprocess_test2.py
...
python preprocess6.py && python preprocess_val6.py && python preprocess_test6.py
```

This generates:
- `preprocessed{i}_train.npz`, `preprocessed{i}_val.npz`, `preprocessed{i}_test.npz`

---

### ğŸ”¹ Step 2: Explore Data

```bash
python explore.py
```

Generates `split_class_distribution.jpg`

---

### ğŸ”¹ Step 3: Train All Models

```bash
python train.py
```

- Trains all `MultiModalNet{i}` models (i=1 to 6)
- Saves each as `model{i}.pth`
- Plots training vs validation loss as `model{i}_loss.jpg`

---

### ğŸ”¹ Step 4: Evaluate All Models

```bash
python evaluate.py
```

- Prints accuracy, precision, recall, and F1-score for each model
- Saves:
  - `evaluation_metrics_comparison.jpg`
  - `confusion_matrices_comparison.jpg`

---

## ğŸ‘¥ Authors

- Janojit Chakraborty â€” [GitHub](https://github.com/Janojit)
